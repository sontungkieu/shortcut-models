import jax
import jax.experimental
import wandb
import jax.numpy as jnp
import numpy as np
import tqdm
import matplotlib.pyplot as plt
import os
from functools import partial
from absl import app, flags

flags.DEFINE_integer('inference_timesteps', 128,
                     'Number of timesteps for inference.')
flags.DEFINE_integer('inference_generations', 4096,
                     'Number of generations for inference.')
flags.DEFINE_float('inference_cfg_scale', 1.0, 'CFG scale for inference.')


def do_inference(
    FLAGS,
    train_state,
    step,
    dataset,
    dataset_valid,
    shard_data,
    vae_encode,
    vae_decode,
    update,
    get_fid_activations,
    imagenet_labels,
    visualize_labels,
    fid_from_stats,
    truth_fid_stats,
):
    with jax.spmd_mode('allow_all'):
        global_device_count = jax.device_count()
        key = jax.random.PRNGKey(42 + jax.process_index())
        batch_images, batch_labels = next(dataset)
        valid_images, valid_labels = next(dataset_valid)
        if FLAGS.model.use_stable_vae:
            batch_images = vae_encode(key, batch_images)
            valid_images = vae_encode(key, valid_images)
        batch_labels_sharded, valid_labels_sharded = shard_data(
            batch_labels, valid_labels)
        labels_uncond = shard_data(jnp.ones(
            batch_labels.shape, dtype=jnp.int32) * FLAGS.model['num_classes'])  # Null token
        eps = jax.random.normal(key, batch_images.shape)

        def process_img(img):
            # Nhận (N,H,W,C) hoặc (H,W,C). Chỉ cắt batch nếu THỰC SỰ có batch.
            if img.ndim == 4:
                img = img[0]                  # (H,W,C)
            elif img.ndim != 3:
                raise ValueError(
                    f"Unexpected image ndim={img.ndim}, expected 3 or 4")

            # Nếu grayscale với C=1 thì chuyển về (H,W) cho imshow.
            if img.shape[-1] == 1:
                img = img[..., 0]             # (H,W)

            # Nếu dùng Stable-VAE latent -> decode sau khi chuẩn hoá shape
            if FLAGS.model.use_stable_vae:
                img = vae_decode(img[None])[0]  # -> (H,W,3)

            # Chuẩn hoá về [0,1]
            img = jnp.clip(img * 0.5 + 0.5, 0, 1)

            # Trả về NumPy host array cho matplotlib
            return np.array(img)

        # @partial(jax.jit, static_argnums=(5,))
        # def call_model(train_state, images, t, dt, labels, use_ema=True):
        #     if use_ema and FLAGS.model.use_ema:
        #         call_fn = train_state.call_model_ema
        #     else:
        #         call_fn = train_state.call_model
        #     output = call_fn(images, t, dt, labels, train=False)
        #     return output

        @partial(jax.jit, static_argnums=(5,))
        def call_model_with_state(train_state, images, t, dt, labels, use_ema=True):
            if use_ema and FLAGS.model.use_ema:
                call_fn = train_state.call_model_ema
            else:
                call_fn = train_state.call_model
            v, x_cin = call_fn(images, t, dt, labels,
                               train=False, return_activations=False)
            return v, x_cin

        if FLAGS.mode == 'interpolate':
            seed = 5
            eps0 = jax.random.normal(
                jax.random.PRNGKey(seed), batch_images[0].shape)
            eps1 = jax.random.normal(
                jax.random.PRNGKey(seed+1), batch_images[0].shape)
            labels = jnp.ones(FLAGS.batch_size,).astype(jnp.int32) * 555
            i = jnp.linspace(0, 1, FLAGS.batch_size)
            i_neg = np.sqrt(1-i**2)
            x = eps0[None] * i_neg[:, None, None, None] + \
                eps1[None] * i[:, None, None, None]
            t_vector = jnp.full((FLAGS.batch_size, ), 0)
            dt_vector = jnp.zeros_like(t_vector)
            cfg_scale = FLAGS.inference_cfg_scale
            # cái này đang bỏ qua IN(xt) mặc dù gần như chả bao giwof dùng, nói chung là nếu có dùng thì đoạn trong hàm if này chưa đúng
            v, _ = call_model_with_state(
                train_state, x, t_vector, dt_vector, labels)
            x = x + v * 1.0
            x = vae_decode(x)  # Image is in [-1, 1] space.
            x_render = np.array(
                jax.experimental.multihost_utils.process_allgather(x))
            os.makedirs(FLAGS.save_dir, exist_ok=True)
            np.save(FLAGS.save_dir + f'/x_render.npy', x_render)
            breakpoint()

        denoise_timesteps = FLAGS.inference_timesteps
        num_generations = FLAGS.inference_generations
        cfg_scale = FLAGS.inference_cfg_scale
        x0 = []
        x1 = []
        lab = []
        x_render = []
        activations = []
        images_shape = batch_images.shape
        print(
            f"Calc FID for CFG {cfg_scale} and denoise_timesteps {denoise_timesteps}")
        for fid_it in tqdm.tqdm(range(num_generations // FLAGS.batch_size)):
            key = jax.random.PRNGKey(42)
            key = jax.random.fold_in(key, fid_it)
            key = jax.random.fold_in(key, jax.process_index())
            eps_key, label_key = jax.random.split(key)
            x = jax.random.normal(eps_key, images_shape)
            labels = jax.random.randint(
                label_key, (images_shape[0],), 0, FLAGS.model.num_classes)
            x, labels = shard_data(x, labels)
            x0.append(
                np.array(jax.experimental.multihost_utils.process_allgather(x)))
            delta_t = 1.0 / denoise_timesteps
            for ti in range(denoise_timesteps):
                t = ti / denoise_timesteps  # From x_0 (noise) to x_1 (data)
                t_vector = jnp.full((images_shape[0], ), t)
                if FLAGS.model.train_type == 'naive':
                    dt_flow = np.log2(
                        FLAGS.model['denoise_timesteps']).astype(jnp.int32)
                    # Smallest dt.
                    dt_base = jnp.ones(
                        images_shape[0], dtype=jnp.int32) * dt_flow
                else:  # shortcut
                    dt_flow = np.log2(denoise_timesteps).astype(jnp.int32)
                    dt_base = jnp.ones(
                        images_shape[0], dtype=jnp.int32) * dt_flow
                    # print(dt_base)
                t_vector, dt_base = shard_data(t_vector, dt_base)
                if cfg_scale == 1:
                    v, y = call_model_with_state(
                        train_state, x, t_vector, dt_base, labels)
                elif cfg_scale == 0:
                    v, y = call_model_with_state(
                        train_state, x, t_vector, dt_base, labels_uncond)
                else:
                    v_u, y_u = call_model_with_state(
                        train_state, x, t_vector, dt_base, labels_uncond)
                    v_c, y_c = call_model_with_state(
                        train_state, x, t_vector, dt_base, labels)
                    # cùng (x, t, dt), CIN deterministic → y_u ≈ y_c
                    v = v_u + cfg_scale * (v_c - v_u)
                    y = y_u

                if FLAGS.model.train_type == 'consistency':
                    eps = shard_data(jax.random.normal(
                        jax.random.fold_in(eps_key, ti), images_shape))
                    x1pred = x + v * (1-t)
                    x = x1pred * (t+delta_t) + eps * (1-t-delta_t)
                else:
                    x = x + v * delta_t  # Euler sampling.
            x1.append(
                np.array(jax.experimental.multihost_utils.process_allgather(x)))
            lab.append(
                np.array(jax.experimental.multihost_utils.process_allgather(labels)))
            if FLAGS.model.use_stable_vae:
                x = vae_decode(x)  # Image is in [-1, 1] space.
                if num_generations < 10000:
                    x_render.append(
                        np.array(jax.experimental.multihost_utils.process_allgather(x)))
            x = jax.image.resize(
                x, (x.shape[0], 299, 299, 3), method='bilinear', antialias=False)
            x = jnp.clip(x, -1, 1)
            # [devices, batch//devices, 2048]
            acts = get_fid_activations(x)[..., 0, 0, :]
            acts = jax.experimental.multihost_utils.process_allgather(acts)
            acts = np.array(acts)
            activations.append(acts)

            if jax.process_index() == 0:
                activations = np.concatenate(activations, axis=0)
                activations = activations.reshape((-1, activations.shape[-1]))
                mu1 = np.mean(activations, axis=0)
                sigma1 = np.cov(activations, rowvar=False)
                fid = fid_from_stats(
                    mu1, sigma1, truth_fid_stats['mu'], truth_fid_stats['sigma'])
                print(f"FID is {fid}")
                print(f"FID is {fid}")
                print(f"FID is {fid}")

                # =============== NEW: log ảnh sinh ra lên W&B ===============
                # Chỉ log khi mình thực sự có x_render (dùng Stable VAE và num_generations nhỏ)
                if len(x_render) > 0:
                    # x_render: list các tensor [num_hosts, local_batch, H, W, C]
                    # [num_hosts * iters, local_batch, H, W, C]
                    x_render_np = np.concatenate(x_render, axis=0)
                    # [N, H, W, C]
                    x_render_np = x_render_np.reshape(-1,
                                                      *x_render_np.shape[-3:])

                    # Map từ [-1,1] -> [0,1] cho W&B
                    x_render_np = np.clip(x_render_np * 0.5 + 0.5, 0.0, 1.0)

                    # Lấy tối đa 64 ảnh đầu để log
                    max_log = min(64, x_render_np.shape[0])
                    samples = x_render_np[:max_log]

                    # Tạo list wandb.Image
                    sample_images = [wandb.Image(img) for img in samples]

                    # Nếu bạn có biến `step` (truyền vào do_inference), có thể dùng,
                    # còn không thì bỏ `step=` để W&B tự tăng step.
                    wandb.log(
                        {"inference/samples": sample_images},
                        step=int(step) if step is not None else None,
                    )
                # ============================================================

                if FLAGS.save_dir is not None:
                    os.makedirs(FLAGS.save_dir, exist_ok=True)
                    if len(x_render) > 0:
                        x_render_np = np.concatenate(x_render, axis=0)
                        np.save(FLAGS.save_dir + f'/x_render.npy', x_render_np)

                    # x0 = np.concatenate(x0, axis=0)
                    # x1 = np.concatenate(x1, axis=0)
                    # lab = np.concatenate(lab, axis=0)
                    # os.makedirs(FLAGS.save_dir, exist_ok=True)
                    # np.save(FLAGS.save_dir + f'/x0.npy', x0)
                    # np.save(FLAGS.save_dir + f'/x1.npy', x1)
                    # np.save(FLAGS.save_dir + f'/lab.npy', lab)
